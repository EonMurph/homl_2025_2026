{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec02c415-becb-4625-bd39-7eea8a052bb2",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac60507",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e1f940-0d5d-4803-8cbf-0babfd052440",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80695a96-813d-4cd5-b9bd-081fe4202531",
   "metadata": {},
   "source": [
    "## Understand the business problem\n",
    "\n",
    "We are a small company, making loans in a competitive market. We want to  speed-up loan decisions and reduce the number of people who default on their loans."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602dab97-7e9a-4769-a7a8-cb36f7bbd91d",
   "metadata": {},
   "source": [
    "## Select performance measures\n",
    "\n",
    "- This is Supervised Learning of a Binary Classifier.\n",
    "- We will measure accuracy.\n",
    "- We will compare with a majority-class classifier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7469813b-e0c5-45b1-8f34-c4b60d89fcbe",
   "metadata": {},
   "source": [
    "## Acquire a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657d228d-8009-4542-95c6-b83c3dcd504b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    base_dir = \"./drive/My Drive/Colab Notebooks/\" # You may need to change this, depending on where your notebooks are on Google Drive\n",
    "else:\n",
    "    base_dir = \".\"\n",
    "dataset_dir = os.path.join(base_dir, \"datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19252902",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(dataset_dir, \"loans.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df17b621-fcb4-4f28-9e30-c289ec97864a",
   "metadata": {},
   "source": [
    "## Take a cheeky look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71f1dc4-3670-49d2-b1dd-682a66caa0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f73c392-1a79-4b33-97e1-d37780976c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44849f9-c3dc-4c81-b46a-a17135f88527",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f44d72-24cd-4d31-b4f4-c255cfd31f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74afefee-d65e-423e-9619-cb43a22c2e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.columns:\n",
    "    if not is_numeric_dtype(df[column]):\n",
    "        print(column, df[column].value_counts())\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f7826c-4af8-4d3d-9817-e41267ae9a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proportion of the dataset whose loan was approved\n",
    "\n",
    "print((df[\"Loan_Decision\"] == \"Y\").sum() / df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4704dd-2736-4d81-80bb-c9dd2b5330b4",
   "metadata": {},
   "source": [
    "Observations\n",
    "\n",
    "1. We have numeric-valued, Boolean-valued and nominal-valued features.\n",
    "2. Loan_id is not a feature: it is used purely for identification. It does not describe the applicant.\n",
    "3. We have 6 features with missing values: Sex, Married, Dependents, Self_Employed, Loan_Amount, Loan_Amount_Term. If you think they are invalid, you can delete those examples. Check with your domain expert. I'm going to assume that our domain expert tells us that it is invalid to apply for a loan but to fail to supply a Loan_Amount or a Loan_Term. So we will delete these. Happily, there aren't too many of them.\n",
    "4. The target is Loan_Decision. Fortunately, it does not have missing values. (If it did, we'd delete those examples.)\n",
    "5. There are some extreme values. If you think they are invalid (e.g. typos), then delete those rows. Check with your domain expert! I'm going to assume that our domain expert tells us that it is invalid to ask for a Loan_Term of more than 360. So we will delete these."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67e20ad-8c1c-4e54-b7d7-a46e0e5bd99e",
   "metadata": {},
   "source": [
    "## Cleanup anything that is simply invalid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2ed79e-2cd3-4681-a443-a653a9c257e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"Loan_Id\"], inplace=True)\n",
    "\n",
    "df.dropna(subset=[\"Loan_Amount\", \"Loan_Term\"], inplace=True)\n",
    "\n",
    "df = df[df[\"Loan_Term\"] <= 360]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5caed5-c9e2-4a6f-b1d4-0f9dbc49f958",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934d1e2f-a79f-4b60-b761-a2445dc86268",
   "metadata": {},
   "source": [
    "## Split into training set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3e8929-4b4c-4e69-8d94-294bf9ad67cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"Sex\", \"Married\", \"Dependents\", \"Education\", \"Self_Employed\", \"Applicant_Income\", \n",
    "            \"Coapplicant_Income\", \"Loan_Amount\", \"Loan_Term\", \"Property_Area\"]\n",
    "\n",
    "numeric_features = [\"Applicant_Income\", \"Coapplicant_Income\", \"Loan_Amount\", \"Loan_Term\"]\n",
    "boolean_features = [\"Sex\", \"Married\", \"Education\", \"Self_Employed\"]\n",
    "nominal_features = [\"Dependents\", \"Property_Area\"]\n",
    "\n",
    "X = df[features]\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(df[\"Loan_Decision\"])\n",
    "\n",
    "label_encoder.inverse_transform([0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ec8094-9718-4060-874b-3a797415e577",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=df[\"Loan_Decision\"], random_state=rng)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ef849d-bc42-4fc9-8de1-4d958811eaec",
   "metadata": {},
   "source": [
    "##  Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368c3bcb-307c-46ca-b170-4e60b2c5d33f",
   "metadata": {},
   "source": [
    "Do the EDA on a copy of X_train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087cd43e-3d23-4779-ab6f-8ab435a07d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_copy = X_train.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b1dada-4a33-4cf6-a844-ad107a1b7ad0",
   "metadata": {},
   "source": [
    "We would now do visualizations, compute correlation coefficients, and so on.\n",
    "\n",
    "I did this but have excluded it from here to save time and space in the lecture.\n",
    "\n",
    "Among the things I discovered:\n",
    "1. No correlations between the numeric features, with one exception - applicant income and loan amount are moderately positively correlated.\n",
    "2. On their own, the numeric-valued features are not predictive of Loan_Decision. We could remove them, but perhaps they are predictive in combination with other features. So, for now, we'll leave them in.\n",
    "3. Most of the non-numeric features did seem partly predictive of Loan_Decision, e.g. Married people were more likely to get a loan."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b420dda0-68ad-4fa8-80f3-e3a18960e53d",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28263a68-a504-4f22-9786-3e254ce7946e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The applicant's total income\n",
    "X_train_copy[\"Total_Income\"] = X_train_copy[\"Applicant_Income\"] + X_train_copy[\"Coapplicant_Income\"]\n",
    "\n",
    "# How much the applicant would repay in each time period\n",
    "X_train_copy[\"Payments_Per_Period\"] = X_train_copy[\"Loan_Amount\"] / X_train_copy[\"Loan_Term\"]\n",
    "\n",
    "# The payment (above) as a proportion of the applicant's income \n",
    "X_train_copy[\"Proportion_Of_Income\"] = X_train_copy[\"Payments_Per_Period\"] / X_train_copy[\"Total_Income\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e016fe0-cb6b-4e8c-a1bd-05d360b96a9b",
   "metadata": {},
   "source": [
    "We would now do more visualizations and compute more correlation coefficients to see whether these new features are promising or not.\n",
    "\n",
    "I did this but have excluded it from here to save time and space in the lecture. In this case, none of them on their own was predictive of the target. But we might include them later, since they might be useful in combination with other features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a8e583-0e7e-4e40-8dcc-b55fd10328d2",
   "metadata": {},
   "source": [
    "## Preprocess the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aecfd79f-ebab-4e8a-bb07-42fab933578b",
   "metadata": {},
   "source": [
    "From now on, we work on the original data, not the copy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad17c2ee-1ecf-4c7f-88ff-c9fbdf0c6920",
   "metadata": {},
   "source": [
    "### Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e5ab84-24b4-40f2-9efd-4c6840d31fc7",
   "metadata": {},
   "source": [
    "Our EDA earlier will have given some insight into the presence of outliers: we will be able to visualize them in the various charts that we plot.\n",
    "\n",
    "We need to be careful: simple rules-of-thumb may result in too many outliers. For example, one rule-of-thumb is: a numeric value is an outlier if it exceeds a maximum value (e.g. the third quartile plus 1.5 times the inter-quartile-range) or falls below a minimum value (e.g. the first quartile minus 1.5 times the inter-quartile-range). How many values will this treat as outliers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9477e9-2c0c-4344-86a5-972b120dafdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = X_train[numeric_features].quantile(0.25)\n",
    "q3 = X_train[numeric_features].quantile(0.75)\n",
    "iqr =  q3 - q1\n",
    "((X_train[numeric_features] < q1 - 1.5 * iqr) | (X_train[numeric_features] > q3 + 1.5 * iqr)).sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8162f1-381d-47b9-bf2d-f8fc12fb4713",
   "metadata": {},
   "source": [
    "From what I saw in the EDA, I suspect that this is too aggressive. I think the numbers are more like 7 outliers for Applicant_Income, 4-6 for Coapplicant_Income, 0-12 for Loan_Amount, and none for Loan_Term.\n",
    "\n",
    "Despite my reservations, in order to illustrate one solution to outliers, I will define a class that can be included in a pipeline. It clips values to the maximum or minmium. But it can be toggled, so we can try clipping and not clipping as part of the grid search.\n",
    "\n",
    "By including it in the pipeline, it wil apply to both training examples and validation/test examples - this is controversial!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce019804-3d3f-4f46-bde4-6e12248ad674",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Clipper(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, clip=True):\n",
    "        self.clip = clip\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        if self.clip:\n",
    "            q1 = X.quantile(0.25)\n",
    "            q3 = X.quantile(0.75)\n",
    "            iqr =  q3 - q1 \n",
    "            self.min = q1 - 1.5 * iqr\n",
    "            self.max = q3 + 1.5 * iqr\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        if self.clip:\n",
    "            X = X.clip(self.min, self.max, axis=1)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21a186c-b218-4844-9c47-9c993376eac7",
   "metadata": {},
   "source": [
    "### Missing values \n",
    "\n",
    "We still have missing values in Sex, Married, Dependents, and Self_Employed. Our domain expert agrees that we should use the mode for all of them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe30b01b-d4fc-4fbd-a270-6fe1734e27d7",
   "metadata": {},
   "source": [
    "### Scaling numeric-valued features\n",
    "\n",
    "We will let grid search find the best scaler."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a673920-ac0c-437f-a8fc-9ee6245bc3a9",
   "metadata": {},
   "source": [
    "### Converting non-numeric features to numeric.\n",
    "\n",
    "We will use one-hot-encoding. But for feature has only two values, we retain only one of the features that one-hot encoding would give us."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88396a72-1d21-4257-a891-40748b793295",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "\n",
    "We can write classes to insert new features. I will do it for one of the features. The class can be toggled, so we can try with the feature and without."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba58461-3c63-4ae2-8f0e-e3b7cd97df08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InsertProportionOfIncome(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, insert=True):\n",
    "        self.insert = insert\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        if self.insert:\n",
    "            X[\"Proportion_Of_Income\"] = (X[\"Loan_Amount\"] / X[\"Loan_Term\"]) / (X[\"Applicant_Income\"] + X[\"Coapplicant_Income\"]) \n",
    "            \n",
    "            # If the new feature is intended to replace the existing ones, \n",
    "            # you could drop the existing ones here\n",
    "            # X.drop([\"Applicant_Income\", \"Coapplicant_Income\", \"Loan_Amount\", Loan_Term], axis=1)\n",
    "\n",
    "            # If the new feature can produce np.inf, replace those value by np.nan\n",
    "            # X = X.replace( [ np.inf, -np.inf ], np.nan )\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a80b5ec-5928-4680-8e7f-e2e069b65da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer([\n",
    "        (\"num\", Pipeline([(\"proportion_of_income\", InsertProportionOfIncome()),\n",
    "                          (\"outliers\", Clipper()),\n",
    "                          (\"scaler\", None)\n",
    "                          ]), \n",
    "                numeric_features),\n",
    "        (\"nom\", Pipeline([(\"imputer\", SimpleImputer(missing_values=np.nan, strategy=\"most_frequent\")), \n",
    "                          (\"encoder\", OneHotEncoder(drop=\"if_binary\"))]), \n",
    "                nominal_features + boolean_features)],\n",
    "        remainder=\"drop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b113616-b38b-4794-8035-77906970d047",
   "metadata": {},
   "source": [
    "## Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235e3c3f-8d84-4313-adbc-7d6e7e2721da",
   "metadata": {},
   "source": [
    "We must choose our validation method, e.g. holdout or k-fold CV. We have a small amount of data, so we'll choose k-fold with k = 10. We will use stratified k-fold (which is the default when we write cv=10)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eabd482-d25c-473e-ab12-6da9be3597a4",
   "metadata": {},
   "source": [
    "We want to do better than a majority-class classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15517b83-c042-414d-836a-c240cc66326c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = DummyClassifier()\n",
    "\n",
    "dummy.fit(X_train, y_train)\n",
    "\n",
    "np.mean(cross_val_score(dummy, X_train, y_train, scoring=\"accuracy\", cv=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7448bc5f-72b4-44c6-a8ca-1e5e5787c64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(preprocessor, predictor, param_grid, cv, metric):\n",
    "    model = Pipeline([\n",
    "                (\"preprocessor\", preprocessor),\n",
    "                (\"predictor\", predictor)\n",
    "    ])\n",
    "\n",
    "    gs = GridSearchCV(model, param_grid, scoring=metric, cv=cv, n_jobs=-1)\n",
    "\n",
    "    gs.fit(X_train, y_train)\n",
    "\n",
    "    return gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53e1a2d-f4cb-4aac-a787-97e570c03e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_gs = grid_search(\n",
    "    preprocessor = preprocessor, \n",
    "    predictor = KNeighborsClassifier(),\n",
    "    param_grid = {\n",
    "        \"preprocessor__num__proportion_of_income__insert\": [True, False],\n",
    "        \"preprocessor__num__outliers__clip\": [True, False],\n",
    "        \"preprocessor__num__scaler\" : [None, MinMaxScaler(), RobustScaler(), StandardScaler()],\n",
    "        \"predictor__n_neighbors\": range(1, 11) ,\n",
    "        \"predictor__weights\" : [\"uniform\", \"distance\"]\n",
    "    },\n",
    "    cv = 10,\n",
    "    metric = \"accuracy\"\n",
    ")\n",
    "\n",
    "knn_gs.best_params_, knn_gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48928afe-d79e-4835-b508-cbe39f37e42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_gs = grid_search(\n",
    "    preprocessor = preprocessor, \n",
    "    predictor = DecisionTreeClassifier(random_state=rng),\n",
    "    param_grid = {\n",
    "        \"preprocessor__num__proportion_of_income__insert\": [True, False],\n",
    "        \"preprocessor__num__outliers__clip\": [True, False],\n",
    "        \"preprocessor__num__scaler\" : [None],\n",
    "        \"predictor__max_depth\": range(1, 11)                 \n",
    "    },\n",
    "    cv = 10,\n",
    "    metric = \"accuracy\"\n",
    ")\n",
    "\n",
    "decision_tree_gs.best_params_, decision_tree_gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846cf57d-3f53-4158-8f71-29e2bd723da2",
   "metadata": {},
   "source": [
    "Both are a bit more accurate than the majority-class classifier, and the decision tree is a lttle more accurate than kNN. It is also faster than kNN at inference time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10436ee8-f64e-452e-a094-45985d8f6cd2",
   "metadata": {},
   "source": [
    "*(Quite frankly, the learned models are not much better than the majority-class classifier. I would check whether my models are underfitting or overfitting and then fix whichever it is.)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb83f04-d2f3-4129-981d-971c6cc3cd97",
   "metadata": {},
   "source": [
    "## If you're certain you've finished with model selection, then you can use the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2db665-39ae-43fc-9910-9936fdc90709",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(decision_tree_gs.best_estimator_.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78d3900-5abd-495f-83aa-ec5aca133495",
   "metadata": {},
   "source": [
    "## If you decide to deploy, then train on the whole dataset and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fba379-67b4-45dd-995b-8a8337741607",
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_gs.best_estimator_.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6330178-4adb-46dc-8361-713ecb20666c",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(decision_tree_gs.best_estimator_, os.path.join(base_dir, 'models/loan_approval_model.pkl')) # assumes a folder called models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f09111-479a-471a-a0de-67e45bc19e70",
   "metadata": {},
   "source": [
    "You can load a model, e.g. in a different Jupyter Notebook like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd4a54a-0bd4-4ed8-ad7e-3faff5ff903a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load(os.path.join(base_dir, 'models/loan_approval_model.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa59333-a5ad-4d51-b2a2-7eab0571d3e9",
   "metadata": {},
   "source": [
    "Then you can use it for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befbbb64-d415-45b6-8dbc-867d3b6a14e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "applicant = {\"Sex\": \"Male\",\n",
    "             \"Married\": \"Yes\",\n",
    "             \"Dependents\": \"0\",\n",
    "             \"Education\": \"Graduate\",\n",
    "             \"Self_Employed\": \"Yes\",\n",
    "             \"Applicant_Income\": 5818, \n",
    "             \"Coapplicant_Income\": 2160, \n",
    "             \"Loan_Amount\": 184,\n",
    "             \"Loan_Term\": 360,\n",
    "             \"Property_Area\": \"Semiurban\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7004d96b-0a77-4ab7-a2d5-3c54c2a1da7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "decision = model.predict(pd.DataFrame([applicant]))\n",
    "label_encoder.inverse_transform(decision)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07c6d37-c176-4551-97d1-eedd6e68915a",
   "metadata": {},
   "source": [
    "Note the advantage: we saved not just the decison tree but also all the preprocessing code which was in a pipeline with the decision tree. So now, during inference, those same preprocessing steps will be applied. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51523df-e96c-4e43-96ee-16166e2348cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
