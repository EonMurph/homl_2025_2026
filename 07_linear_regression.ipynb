{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec02c415-becb-4625-bd39-7eea8a052bb2",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac60507",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from ipywidgets import interactive\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from sklearn.preprocessing import add_dummy_feature\n",
    "\n",
    "import numpy.linalg as npla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ab9414-9b1d-4f03-ba48-0fdd010dfb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7469813b-e0c5-45b1-8f34-c4b60d89fcbe",
   "metadata": {},
   "source": [
    "## Read in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ec3847-9769-47d3-b550-53d5d885d794",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    base_dir = \"./drive/My Drive/Colab Notebooks/\" # You may need to change this, depending on where your notebooks are on Google Drive\n",
    "else:\n",
    "    base_dir = \".\"\n",
    "dataset_dir = os.path.join(base_dir, \"datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0596f166-1350-472f-bf70-bacdac1fbdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(dataset_dir, \"housing.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179d6efb-651f-403b-bbbc-d27b15a04602",
   "metadata": {},
   "source": [
    "## Split into training set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29697efd-d658-43b3-bc13-32e644f3f69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.2, random_state=rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402c658c-cf73-43a1-856e-08b05cc1bc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"BasementArea\", \"GroundFloorArea\", \"Bedrooms\", \"Condition\"]\n",
    "\n",
    "X_train = train[features]\n",
    "y_train = train[\"SalePrice\"]\n",
    "X_test = test[features]\n",
    "y_test = test[\"SalePrice\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21108ef-2121-4a93-a246-1cf7015d84c4",
   "metadata": {},
   "source": [
    "## Linear Regression using Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df17b621-fcb4-4f28-9e30-c289ec97864a",
   "metadata": {},
   "source": [
    "Scikit-Learn's LinearRegression class is trained using the Normal Equation (see slides). The Normal Equation has no hyperparameters, so we don't need any model selection (validation sets, grid search), and it is scale-invariant, so we don't need a preprocessor for scaling. (Of course, on other datasets, you might have a preprocessor to do other things, e.g. to convert nominal-valued features.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71f1dc4-3670-49d2-b1dd-682a66caa0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78abb843-a806-42e4-beec-9cbd5d7d143f",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726db0d1-0236-45ac-aec4-3e8db63fb638",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model.intercept_, linear_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ab1594-0218-47b0-9d6a-8ff3218fe493",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(linear_model.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b935a7-0ec7-4f03-9283-30511d4e440f",
   "metadata": {},
   "source": [
    "## Interpretability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6ea910-0523-496c-8cab-8b52c1a429fc",
   "metadata": {},
   "source": [
    "The model we have learned is \n",
    "$$\\hat{y} = 4431 + 62 \\times \\mathit{BasementArea} + 103 \\times \\mathit{GroundFloorArea} + -20717 \\times \\mathit{Bedrooms} + 2639 \\times \\mathit{Condition}$$\n",
    "\n",
    "- Do you find that to be interpretable?\n",
    "- Should we condlude that $\\mathit{Condition}$ is the most important feature? Should we conclude that $\\mathit{Bedrooms}$ is an unhelpful feature?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200140a6-4696-4341-88e4-b693ae7e5687",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model_scaled = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"predictor\", LinearRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422e918f-cd58-4db2-a951-a79629f5c7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model_scaled.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27aea6a0-9ac8-48f1-a214-bdc182898445",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model_scaled.named_steps[\"predictor\"].intercept_, linear_model_scaled.named_steps[\"predictor\"].coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f84e2f-c9dd-44e8-955c-fca5da7ee628",
   "metadata": {},
   "source": [
    "This time the model we have learned is \n",
    "$$\\hat{y} = 179966 + 27717 \\times \\mathit{BasementArea (scaled)} + 51958 \\times \\mathit{GroundFloorArea (scaled)} + -16856 \\times \\mathit{Bedrooms (scaled)} + 2979 \\times \\mathit{Condition (scaled)}$$\n",
    "- Now, $\\mathit{GroundFloorArea}$ is the most important feature!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7b5689-8ae7-4a6d-b1ed-90e65c3a865d",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model_scaled.fit(X_train[[\"BasementArea\", \"Bedrooms\", \"Condition\"]], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41acc7e-b4c5-49a1-aa9a-485e5ee01a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model_scaled.named_steps[\"predictor\"].intercept_, linear_model_scaled.named_steps[\"predictor\"].coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a112fe53-413f-497b-a327-64c58c262f81",
   "metadata": {},
   "source": [
    "Without the $\\mathit{GroundFloorArea}$, the model we have learned is \n",
    "$$\\hat{y} = 179966 + 50050 \\times \\mathit{BasementArea (scaled)} + 8539 \\times \\mathit{Bedrooms (scaled)} + 1191 \\times \\mathit{Condition (scaled)}$$\n",
    "- The coefficient for $\\mathit{Bedrooms}$ is no longer negative.\n",
    "- Why will coefficients sometimes be negative?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7f3fcb-fac9-4050-90bb-c4ddece22c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(X_train.corr(numeric_only=True), annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cd0a3e-65cf-4d97-8adf-e1f1f63b1718",
   "metadata": {},
   "source": [
    "The rest of this Jupyter Notebook is devoted to trying to help explain what's going on 'under the bonnet'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c264182-9335-48b9-a53c-a7f7a5a847a8",
   "metadata": {},
   "source": [
    "## Linear Regression - Under the Bonnet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779a6dbf-52ca-4501-95f5-9016edf86507",
   "metadata": {},
   "source": [
    "### Linear Regression with one feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f73c392-1a79-4b33-97e1-d37780976c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = sns.scatterplot(data=train, x=\"GroundFloorArea\", y=\"SalePrice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44849f9-c3dc-4c81-b46a-a17135f88527",
   "metadata": {},
   "outputs": [],
   "source": [
    "def J(X, y, b, w):\n",
    "    return np.mean((b + X.dot(w) - y) ** 2) / 2.0\n",
    "    \n",
    "def show_linear_model(b, w):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_xlim(0, 6000)\n",
    "    ax.set_ylim(0, 700000)\n",
    "    sns.scatterplot(data=train, x=\"GroundFloorArea\", y=\"SalePrice\", ax=ax)\n",
    "    xvals = np.array([0,6000])\n",
    "    sns.lineplot(x=xvals, y=b + w*xvals, color='g', ax=ax)\n",
    "    ax.text(3400, 650000, \"Loss: \" + str(J(X_train[[\"GroundFloorArea\"]], y_train, b, np.array([w]))))\n",
    "\n",
    "interactive_plot = interactive(show_linear_model, b=(0,700000, 5000), w=(-1000,1000,10))\n",
    "interactive_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45fa46e-8e4e-478d-89db-07d875f1c89f",
   "metadata": {},
   "source": [
    "### Linear Regression with two features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ec8094-9718-4060-874b-3a797415e577",
   "metadata": {},
   "outputs": [],
   "source": [
    "def J(X, y, b, w):\n",
    "    return np.mean((b + X.dot(w) - y) ** 2) / 2.0\n",
    "    \n",
    "def show_linear_model(b, w1, w2):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.set_xlabel(\"GroundFloorArea\")\n",
    "    ax.set_xlim(0, 6000)\n",
    "    ax.set_ylabel(\"BasementArea\")\n",
    "    ax.set_ylim(0, 6000)\n",
    "    ax.set_zlabel(\"SalePrice\")\n",
    "    ax.set_zlim(0, 700000)\n",
    "    ax.scatter(train[\"GroundFloorArea\"],  train[\"BasementArea\"], train[\"SalePrice\"], color=\"green\")\n",
    "    xvals = np.linspace(0, 6000, 2)\n",
    "    yvals = np.linspace(0, 6000, 2)\n",
    "    xxvals, yyvals = np.meshgrid(xvals, yvals)\n",
    "    ax.plot_surface(xxvals, yyvals, b + w1*xxvals + w2*yyvals, color=(0, 0, 1, 0.2))\n",
    "    ax.text(200, 0, 1000000, \"Loss: \" + str(J(X_train[[\"GroundFloorArea\", \"BasementArea\"]], y_train, b, np.array([w1, w2]))))\n",
    "\n",
    "\n",
    "interactive_plot = interactive(show_linear_model, b=(0, 700000, 5000), w1=(-1000,1000,10), w2=(-1000,1000,10))\n",
    "interactive_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e062e190-c7fd-4cc4-ae7b-5808c3a26810",
   "metadata": {},
   "source": [
    "### MSE is a Convex Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3cae81-f99a-412e-ba1f-6d7473cc21ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = StandardScaler().fit_transform(X_train[[\"GroundFloorArea\", \"BasementArea\"]])\n",
    "fig = plt.figure() \n",
    "plt.xlabel(\"w1\")\n",
    "plt.ylabel(\"w2\")\n",
    "xvals = np.linspace(-100000000, 100000000, 100)\n",
    "yvals = np.linspace(-100000000, 100000000, 100)\n",
    "xxvals, yyvals = np.meshgrid(xvals, yvals)\n",
    "zs = np.array([J(X_train_scaled, y_train, 0, np.array([w1, w2]))\n",
    "                 for w1, w2 in zip(xxvals.flatten(), yyvals.flatten())])\n",
    "zvals = zs.reshape(xxvals.shape)\n",
    "C = plt.contour(xxvals, yyvals, zvals, 15, colors = \"black\")\n",
    "plt.clabel(C, inline=1, fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce493f9-a0c8-40b4-8865-560e77b585a2",
   "metadata": {},
   "source": [
    "(The above plot assumed b=0 so that we could use a 2D diagram, and it shows the values of w1 and w2 for scaled features, not the original feature values.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ab9a79-9d98-4296-9eaa-0a182bc86373",
   "metadata": {},
   "source": [
    "### Let's \"roll our own\" linear regressor using the Normal Equation - unnecessary - but informative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28263a68-a504-4f22-9786-3e254ce7946e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OurLinearRegressor_v1():\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        X = add_dummy_feature(X)\n",
    "        self.param_vals = npla.inv(X.T.dot(X)).dot(X.T).dot(y)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X = add_dummy_feature(X)\n",
    "        return X.dot(self.param_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30316d72-343d-412a-be02-a00fa95b5477",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model = OurLinearRegressor_v1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7055bcc8-85f5-44d5-a223-c14da2c449dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6d1149-40f1-4b1a-a1f1-889d89b24c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model.param_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44493cd9-22d7-4c2c-b4f4-1f918b31eb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(linear_model.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a926d8e-6556-40e5-b325-2e912d210720",
   "metadata": {},
   "source": [
    "But there's a problem. The normal equation requires that `X_train` has an inverse. But it might not. There is something called the pseudo-inverse which we can often use instead. So here's a more robust way of writing this class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4694a35c-bc25-491b-a84d-63e0ad5a2b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OurLinearRegressor_v2():\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        X = add_dummy_feature(X)\n",
    "        self.param_vals = npla.inv(X.T.dot(X)).dot(X.T).dot(y)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X = add_dummy_feature(X)\n",
    "        return X.dot(self.param_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff4831e-f23e-46af-ac0a-cd52c3387b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model = OurLinearRegressor_v2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dbd329-d267-441d-8d3f-f1a6e75392c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929b3489-00d0-4dd6-9b88-e6e66176504b",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model.param_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd513b9-1124-4077-8c4f-6167837cba57",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(linear_model.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed131ec2-25dd-45a9-9fde-74a78e620058",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
