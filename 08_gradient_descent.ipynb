{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec02c415-becb-4625-bd39-7eea8a052bb2",
   "metadata": {},
   "source": [
    "# Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac60507",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from ipywidgets import interactive, fixed\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from sklearn.preprocessing import add_dummy_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256cbed8-8868-4edb-b932-46791646c1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7469813b-e0c5-45b1-8f34-c4b60d89fcbe",
   "metadata": {},
   "source": [
    "## Read in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ec3847-9769-47d3-b550-53d5d885d794",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    base_dir = \"./drive/My Drive/Colab Notebooks/\" # You may need to change this, depending on where your notebooks are on Google Drive\n",
    "else:\n",
    "    base_dir = \".\"\n",
    "dataset_dir = os.path.join(base_dir, \"datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0596f166-1350-472f-bf70-bacdac1fbdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(dataset_dir, \"housing.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179d6efb-651f-403b-bbbc-d27b15a04602",
   "metadata": {},
   "source": [
    "## Split into training set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29697efd-d658-43b3-bc13-32e644f3f69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.2, random_state=rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402c658c-cf73-43a1-856e-08b05cc1bc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"BasementArea\", \"GroundFloorArea\", \"Bedrooms\", \"Condition\"]\n",
    "\n",
    "X_train = train[features]\n",
    "y_train = train[\"SalePrice\"]\n",
    "X_test = test[features]\n",
    "y_test = test[\"SalePrice\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21108ef-2121-4a93-a246-1cf7015d84c4",
   "metadata": {},
   "source": [
    "## Linear Regression using Scikit-Learn - reminder - used the Normal Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71f1dc4-3670-49d2-b1dd-682a66caa0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78abb843-a806-42e4-beec-9cbd5d7d143f",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726db0d1-0236-45ac-aec4-3e8db63fb638",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model.intercept_, linear_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ab1594-0218-47b0-9d6a-8ff3218fe493",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(linear_model.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c264182-9335-48b9-a53c-a7f7a5a847a8",
   "metadata": {},
   "source": [
    "## Gradient Descent - features must be scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670c3cb8-981c-4910-b1c5-c926331fcf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0234c38-8e52-47c0-b18f-e7d36b01229c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = add_dummy_feature(X_train_scaled)\n",
    "X_test_scaled = add_dummy_feature(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779a6dbf-52ca-4501-95f5-9016edf86507",
   "metadata": {},
   "source": [
    "### Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f73c392-1a79-4b33-97e1-d37780976c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function for OLS regression (assumes X contains all 1s in its first column)\n",
    "def J(X, y, params):\n",
    "    return np.mean((X.dot(params) - y) ** 2) / 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44849f9-c3dc-4c81-b46a-a17135f88527",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_gradient_descent(X, y, alpha, num_iterations):\n",
    "    \n",
    "    m, n = X.shape\n",
    "    params = rng.standard_normal(n) \n",
    "    Jvals = np.zeros(num_iterations)\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        params -= (alpha / m) * X.T.dot(X.dot(params) - y)\n",
    "        Jvals[i] = J(X, y, params)\n",
    " \n",
    "    return params, Jvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f3a3ee-6763-4a65-b2d8-544c96e945f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the Batch Gradient Descent\n",
    "params, Jvals = batch_gradient_descent(X_train_scaled, y_train, alpha = 0.03, num_iterations = 200)\n",
    "\n",
    "# Display params (bias and weights)\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ff23a0-d19c-4321-9241-157d0e26dfd0",
   "metadata": {},
   "source": [
    "(We used the Normal Equation -above- on unscaled data and BGD on scaled data - so the results differ.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6e2199-c318-440c-bdf7-99af56eca20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(Jvals):\n",
    "    fig, ax = plt.subplots(figsize=(20,8))\n",
    "    xvals = np.linspace(1, Jvals.size, Jvals.size)\n",
    "    ax = sns.scatterplot(x=xvals, y=Jvals)\n",
    "    ax.set_title(\"J during learning\")\n",
    "    ax.set_ylabel(\"J\")\n",
    "    ax.set_xlabel(\"Number of iterations\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced4ba05-92dd-41ee-aa33-41bfe5cc1ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(np.minimum(Jvals, 1.75e10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddabc3d-5e1b-4c4f-8128-98e662a4a884",
   "metadata": {},
   "source": [
    "Below is an interactive version - we can see the effect of scaling and we can play with the learning rate. (The crashes/nonsensical answers are deliberate!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54df8e44-1d52-4f7a-aee6-d86f139ff3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bgd(X, y, scale=True, alpha=0.03):\n",
    "    # Scale the data, if requested\n",
    "    if scale:\n",
    "        X = StandardScaler().fit_transform(X)\n",
    "    # Add the extra column to X\n",
    "    X = add_dummy_feature(X)\n",
    "    # Run the Batch Gradient Descent\n",
    "    params, Jvals = batch_gradient_descent(X, y, alpha, num_iterations = 3000)\n",
    "    # Display bias and weights\n",
    "    print(\"Parameters: \", params)\n",
    "    fig, ax = plt.subplots(figsize=(20,8))\n",
    "    xvals = np.linspace(1, Jvals.size, Jvals.size)\n",
    "    ax = sns.scatterplot(x=xvals, y=Jvals)\n",
    "    ax.set_title(\"J during learning\")\n",
    "    ax.set_ylabel(\"J\")\n",
    "    ax.set_xlabel(\"Number of iterations\")\n",
    "    # plt.ylim(3500, 50000)\n",
    "    plt.show()\n",
    "    \n",
    "interactive_plot = interactive(bgd, {'manual': True},\n",
    "    X=fixed(X_train), y=fixed(y_train),\n",
    "    scale=True, \n",
    "    alpha=[(\"0.00009\", 0.00009), (\"0.0009\", 0.0009), (\"0.009\", 0.009), (\"0.09\", 0.09), (\"0.9\", 0.9)]) \n",
    "interactive_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45fa46e-8e4e-478d-89db-07d875f1c89f",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ec8094-9718-4060-874b-3a797415e577",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_gradient_descent(X, y, alpha, num_epochs):\n",
    "\n",
    "    np.random.seed(2)\n",
    "    m, n = X.shape\n",
    "    params = rng.standard_normal(n) \n",
    "    Jvals = np.zeros(num_epochs * m)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        perm = rng.permutation(m)\n",
    "        for i in perm:\n",
    "            x_i = X[i:i+1]\n",
    "            y_i = y[i:i+1]\n",
    "            params -= alpha * x_i.T.dot(x_i.dot(params) - y_i)\n",
    "            Jvals[epoch * m + i] = J(X, y, params)\n",
    " \n",
    "    return params, Jvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8251816-3ae4-4297-b6eb-b6775b6c52e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the Stochastic Gradient Descent\n",
    "params, Jvals = stochastic_gradient_descent(X_train_scaled, y_train, alpha = 0.003, num_epochs = 200)\n",
    "\n",
    "# Display params\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd1e535-dce9-44ee-b76b-26cd2655dba1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_loss(np.minimum(Jvals[:10000], 1.75e10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e062e190-c7fd-4cc4-ae7b-5808c3a26810",
   "metadata": {},
   "source": [
    "### SGD with Simulated Annealing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3cae81-f99a-412e-ba1f-6d7473cc21ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_schedule(t):\n",
    "    return 5 / (t + 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a39bf0-c96d-442a-9707-91edcab8369f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd_simulated_annealing(X, y, alpha, num_epochs):\n",
    "\n",
    "    np.random.seed(2)\n",
    "    m, n = X.shape\n",
    "    params = rng.standard_normal(n) \n",
    "    Jvals = np.zeros(num_epochs * m)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        perm = rng.permutation(m)\n",
    "        for i in perm:\n",
    "            x_i = X[i:i+1]\n",
    "            y_i = y[i:i+1]\n",
    "            alpha = learning_schedule(epoch * m + i)\n",
    "            params -= alpha * x_i.T.dot(x_i.dot(params) - y_i)\n",
    "            Jvals[epoch * m + i] = J(X, y, params)\n",
    " \n",
    "    return params, Jvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a3234e-79b1-46f9-86c7-9308ec53012d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the Stochastic Gradient Descent with Simulated Annealing\n",
    "params, Jvals = sgd_simulated_annealing(X_train_scaled, y_train, alpha = 0.003, num_epochs = 200)\n",
    "\n",
    "# Display params\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0ad7a8-87cb-49a4-b933-05ecab94b873",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_loss(np.minimum(Jvals[:10000], 1.75e10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ab9a79-9d98-4296-9eaa-0a182bc86373",
   "metadata": {},
   "source": [
    "### Mini-Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28263a68-a504-4f22-9786-3e254ce7946e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mini_batch_gradient_descent(X, y, alpha, num_epochs, batch_size):\n",
    "\n",
    "    np.random.seed(2)\n",
    "    m, n = X.shape\n",
    "    params = rng.standard_normal(n) \n",
    "    Jvals = np.zeros(num_epochs * (m // batch_size))\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        perm = rng.permutation(m)\n",
    "        for i in range(m // batch_size):\n",
    "            indices = perm[i*batch_size:i*batch_size+batch_size]\n",
    "            X_batch = X[perm]\n",
    "            y_batch = y.iloc[perm]\n",
    "            params -= (alpha / m) * X_batch.T.dot(X_batch.dot(params) - y_batch)\n",
    "            Jvals[epoch * (m // batch_size) + i] = J(X, y, params)\n",
    " \n",
    "    return params, Jvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30316d72-343d-412a-be02-a00fa95b5477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the Mini-Batch Gradient Descent\n",
    "params, Jvals = mini_batch_gradient_descent(X_train_scaled, y_train, alpha = 0.003, num_epochs = 200, batch_size = 32)\n",
    "\n",
    "# Display params\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fc2855-8681-4998-a7a8-806350a64ff1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_loss(np.minimum(Jvals[:10000], 1.75e10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2093a9a-d74b-46e8-a41b-62520f797d5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
