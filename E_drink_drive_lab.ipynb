{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec02c415-becb-4625-bd39-7eea8a052bb2",
   "metadata": {},
   "source": [
    "# E: Drink-Drive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5aa1cf2-f40d-44ec-9086-2174c375dde7",
   "metadata": {},
   "source": [
    "There are no hints and no answers in this lab sheet. Towards the end of the session, we will discuss a solution together - so you can compare yours with the one I will present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d926cf00-e077-427f-9893-b7ff4965d8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80695a96-813d-4cd5-b9bd-081fe4202531",
   "metadata": {},
   "source": [
    "## The business problem\n",
    "\n",
    "Your friend has an idea for an app. At the close of an evening's socialising, users can enter a few details into an on-screen form and the app will advise them whether they are safe to drive home or whether they are over the drink-drive limit. Your friend will take care of building the app architecture. He has asked you to train a model that can make under-the-limit/over-the-limit predictions. Accuracy is essential. If the model can explain its predictions, so much the better.\n",
    "\n",
    "## Performance measures\n",
    "\n",
    "You realise that this is a binary classification problem and that accuracy is the main metric to use in the evaluation. It makes sense to compare against a baseline - a dummy classifier that predicts the majority-class of the training examples. \n",
    "\n",
    "## Dataset\n",
    "\n",
    "You speak to your lecturer about this and he provides you with a CSV file (`drink_drive.csv`). This file was collected by two students during their PhD in Trinity. The students bought a large box of breathalyser devices. Over several evenings, they visited Dublin pubs and asked customers to be part of a dataset. Each row contains the responses of a customer to various questions, which become the features of the dataset. After responding to the questions, the customer blew into a breathalyser to determine whether they were under or over the drink-drive limit - \"No\" or \"Yes\" respectively. This is the 'ground truth'. It becomes the target value.\n",
    "\n",
    "Each row in the CSV file contains 9 pieces of data, which your lecturer explains as follows:\n",
    "- age_yrs: The person's age.\n",
    "- height_cm: Their height.\n",
    "- weight_kg: Their weight\n",
    "- duration_mins: How long they've been drinking today (the time between the first sip of the first drink and the most recent sip of the most recent drink).\n",
    "- elapsed_mins: How long since their last sip.\n",
    "- sex: Biological sex.\n",
    "- last_meal: the nature of their most recent meal, e.g. Snack, Lunch or Full (a full meal - a dinner).\n",
    "\n",
    "(In truth, this dataset is too small for Machine Learning - fewer than 100 examples. You cannot do ML on this size of dataset. We're using it for this lab because it's fun and throws up several interesting issues. The two students with their supervisor and me did not care about learning an accurate predictive model. We were using it in our research on XAI. We were able to demonstrate an interesting new way of explaining a model's predictions - and, for this, the small dataset was just about adequate.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "657d228d-8009-4542-95c6-b83c3dcd504b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    base_dir = \"./drive/My Drive/Colab Notebooks/\" # You may need to change this, depending on where your notebooks are on Google Drive\n",
    "else:\n",
    "    base_dir = \".\"\n",
    "dataset_dir = os.path.join(base_dir, \"datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "19252902",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(dataset_dir, \"drink_drive.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2fa87b-3111-40ff-a445-af73e912356d",
   "metadata": {},
   "source": [
    "Now you're on your own. You know the steps: take a cheeky look, clean anything that's invalid, split, EDA, Feature Engineering, Preprocessing, Model Selection and, after any necessary iteration, finally Error Estimation. To speed things along, you can skip EDA. But, include some ensembles this time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df17b621-fcb4-4f28-9e30-c289ec97864a",
   "metadata": {},
   "source": [
    "## Take a cheeky look"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67e20ad-8c1c-4e54-b7d7-a46e0e5bd99e",
   "metadata": {},
   "source": [
    "## Cleanup anything that is simply invalid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934d1e2f-a79f-4b60-b761-a2445dc86268",
   "metadata": {},
   "source": [
    "## Split into training set and test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ef849d-bc42-4fc9-8de1-4d958811eaec",
   "metadata": {},
   "source": [
    "##  Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368c3bcb-307c-46ca-b170-4e60b2c5d33f",
   "metadata": {},
   "source": [
    "Skip this step. Otherwise, you won't finish during the lab session."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b420dda0-68ad-4fa8-80f3-e3a18960e53d",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd77e27-1e11-4d94-b34a-98752bc8100d",
   "metadata": {},
   "source": [
    "Don't spend too long on this step - we practised it in a previous lab. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a8e583-0e7e-4e40-8dcc-b55fd10328d2",
   "metadata": {},
   "source": [
    "## Preprocess the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b113616-b38b-4794-8035-77906970d047",
   "metadata": {},
   "source": [
    "## Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb83f04-d2f3-4129-981d-971c6cc3cd97",
   "metadata": {},
   "source": [
    "## Error Estimation - evaluate on the the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adba61e-b5f6-48a8-8958-dd66372a5a44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
