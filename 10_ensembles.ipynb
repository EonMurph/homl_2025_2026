{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec02c415-becb-4625-bd39-7eea8a052bb2",
   "metadata": {},
   "source": [
    "# Ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1609757-d5dc-4f5a-8add-eaeb10ea0480",
   "metadata": {},
   "source": [
    "Warning! Some of the code cells in the Notebook will take a very long time to run. To speed things up a little, I've used only small number of hyperparameter values in the grid searches and I've used cv=5, instead of cv=10. But it is still slow. You might consider running it on Google Colab for more speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac60507",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ec2334-cc46-4bcc-9d01-0d086e8759bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7469813b-e0c5-45b1-8f34-c4b60d89fcbe",
   "metadata": {},
   "source": [
    "## Read in wine dataset, take a cheeky look, and split it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139d0d44-21c7-48c6-af92-748565c04458",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    base_dir = \"./drive/My Drive/Colab Notebooks/\" # You may need to change this, depending on where your notebooks are on Google Drive\n",
    "else:\n",
    "    base_dir = \".\"\n",
    "dataset_dir = os.path.join(base_dir, \"datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19252902",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(dataset_dir, \"wines.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808ef6ba-0f5c-49d2-8581-55b6b069fe4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a84059-463e-420d-aad0-11c019916641",
   "metadata": {},
   "source": [
    "colour = 0 are red wines, colour = 1 are white wines. It is essential that train_test_split shuffles because red wines come first and then white wines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3d7db1-d680-4aba-a9a0-c1a4bf7a4626",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13982dc-4666-467a-a923-4075c602e891",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58eefb51-71c9-47ca-9ce8-16542fc57e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a59dae-c6fd-4af8-8cd9-19c70b497584",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"quality\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74dd4a15-7a48-4df3-8f22-c794b9ded7b8",
   "metadata": {},
   "source": [
    "We could use regression: we're predicting quality and it is numeric. Or we could use multiclass classification: there is a finite set of quality labels. Maybe we should use ordinal classification (if we knew how!), since the labels are ordered. \n",
    "\n",
    "We will use multiclass classification. \n",
    "\n",
    "Stratification is essential, since the dataset is very unbalanced. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6a0d58-d0f8-4756-80c3-963333277196",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.2, stratify=df[\"quality\"], random_state=rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b6d86c-966b-449b-829e-7108de042b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"colour\", \"fixed acidity\", \"volatile acidity\", \"citric acid\",\n",
    "            \"residual sugar\", \"chlorides\", \"free sulfur dioxide\",\n",
    "            \"total sulfur dioxide\", \"density\", \"pH\", \"sulphates\", \"alcohol\"]\n",
    "\n",
    "X_train = train[features]\n",
    "y_train = train[\"quality\"]\n",
    "X_test = test[features]\n",
    "y_test = test[\"quality\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765ae8aa-47a0-4461-8b67-5c4f7042b692",
   "metadata": {},
   "source": [
    "## Majority-class classifier - we want to beat this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6231cb50-66b0-4d0d-ad71-67592f66b0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = DummyClassifier()\n",
    "\n",
    "dummy.fit(X_train, y_train)\n",
    "\n",
    "np.mean(cross_val_score(dummy, X_train, y_train, scoring=\"accuracy\", cv=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df17b621-fcb4-4f28-9e30-c289ec97864a",
   "metadata": {},
   "source": [
    "## Decision Tree, kNN, Multinomial Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671433cb-da81-43f7-9326-8a7502e1054d",
   "metadata": {},
   "source": [
    "A handy function that we will make much use - it does model selection using grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bccd14-0dd8-4412-bff7-816dcd81f27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(preprocessor, predictor, param_grid, cv, metric, X_train, y_train):\n",
    "    model = Pipeline([\n",
    "                (\"preprocessor\", preprocessor),\n",
    "                (\"predictor\", predictor)\n",
    "    ])\n",
    "\n",
    "    gs = GridSearchCV(model, param_grid, scoring=metric, cv=cv, n_jobs=-1)\n",
    "\n",
    "    gs.fit(X_train, y_train)\n",
    "\n",
    "    return gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71f1dc4-3670-49d2-b1dd-682a66caa0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_gs = grid_search(\n",
    "    preprocessor = None,\n",
    "    predictor = DecisionTreeClassifier(random_state=rng),\n",
    "    param_grid = {\n",
    "        \"predictor__max_depth\": range(1, 11)                 \n",
    "    },\n",
    "    cv = 5,\n",
    "    metric = \"accuracy\",\n",
    "    X_train = X_train,\n",
    "    y_train = y_train\n",
    ")\n",
    "\n",
    "decision_tree_gs.best_params_, decision_tree_gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd06ea6-9c12-4af0-808c-611a1da15a9f",
   "metadata": {},
   "source": [
    "For kNN and Logistic Regresssion, we'll use standardization to scale the features. We could use grid search to choose between various scaling methods - but we won't bother this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae1b3a3-3585-403a-a08b-fd1a17736cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_gs = grid_search(\n",
    "    preprocessor = StandardScaler(), \n",
    "    predictor = KNeighborsClassifier(),\n",
    "    param_grid = {\n",
    "        \"predictor__n_neighbors\": range(1, 11)\n",
    "    },\n",
    "    cv = 5,\n",
    "    metric = \"accuracy\",\n",
    "    X_train = X_train,\n",
    "    y_train = y_train\n",
    ")\n",
    "\n",
    "knn_gs.best_params_, knn_gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1096c7f0-7629-4cce-acbc-b26131056849",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_gs = grid_search(\n",
    "    preprocessor = StandardScaler(), \n",
    "    predictor = LogisticRegression(penalty=None, max_iter=600, random_state=rng),\n",
    "    param_grid = {},\n",
    "    cv = 5,\n",
    "    metric = \"accuracy\",\n",
    "    X_train = X_train,\n",
    "    y_train = y_train\n",
    ")\n",
    "\n",
    "logistic_gs.best_params_, logistic_gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae0368f-7d0e-47bf-bd53-6f4431e3b750",
   "metadata": {},
   "source": [
    "## Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261b5857-b30c-4c0d-ab82-5fe902ed23d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_gs = grid_search(\n",
    "    preprocessor = StandardScaler(), \n",
    "    predictor = VotingClassifier(estimators=[(\"tree\", DecisionTreeClassifier(random_state=rng)), \n",
    "                                             (\"knn\", KNeighborsClassifier()),\n",
    "                                             (\"logistic\", LogisticRegression(penalty=None, max_iter=600, random_state=rng))],\n",
    "                                 n_jobs=-1),\n",
    "    param_grid = {\n",
    "        \"predictor__tree__max_depth\": range(1, 4),\n",
    "        \"predictor__knn__n_neighbors\": range(10, 13) ,\n",
    "    },\n",
    "    cv = 5,\n",
    "    metric = \"accuracy\",\n",
    "    X_train = X_train,\n",
    "    y_train = y_train\n",
    ")\n",
    "\n",
    "voting_gs.best_params_, voting_gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ad86fd-216f-4479-8e92-0201f7e5d7cc",
   "metadata": {},
   "source": [
    "This simple ensemble is worse than kNN on its own. Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d736e0f2-6794-4345-9b1a-8a90a6f37442",
   "metadata": {},
   "source": [
    "## Bagging (a) with kNN, (b) with Decision Trees = Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ddbdd5-1ce9-440c-8e02-27d462f5ef42",
   "metadata": {},
   "source": [
    "(I also tried bagging with Logistic Regression but its accuracy wasn't great.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fe9c16-72de-4d9a-94e2-78815c3f0427",
   "metadata": {},
   "outputs": [],
   "source": [
    "bagging_knn_gs = grid_search(\n",
    "    preprocessor = StandardScaler(), \n",
    "    predictor = BaggingClassifier(estimator=KNeighborsClassifier(), n_jobs=-1),\n",
    "    param_grid = {\n",
    "        \"predictor__n_estimators\": [100, 150, 200],\n",
    "        \"predictor__estimator__n_neighbors\": range(1, 4) ,\n",
    "    },\n",
    "    cv = 5,\n",
    "    metric = \"accuracy\",\n",
    "    X_train = X_train,\n",
    "    y_train = y_train\n",
    ")\n",
    "\n",
    "bagging_knn_gs.best_params_, bagging_knn_gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703823e2-2cad-4c8e-8a6b-f94939785d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_gs = grid_search(\n",
    "    preprocessor = None, \n",
    "    predictor = RandomForestClassifier(n_jobs=-1, random_state=rng),\n",
    "    param_grid = {\n",
    "        \"predictor__n_estimators\": [250, 300, 350],\n",
    "        \"predictor__max_depth\": range(10, 13) ,\n",
    "    },\n",
    "    cv = 5,\n",
    "    metric = \"accuracy\",\n",
    "    X_train = X_train,\n",
    "    y_train = y_train\n",
    ")\n",
    "\n",
    "random_forest_gs.best_params_, random_forest_gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccfeb7a-1a79-4fa1-972d-e849078b215d",
   "metadata": {},
   "source": [
    "## AdaBoost with Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d848b9b-8537-4a57-a22f-18ade3c2da47",
   "metadata": {},
   "source": [
    "The models within an AdaBoost ensemble must allow weighted examples. This excludes kNN but does include Decision Trees (the default) and Logistic Regression. (Again I tried it wih Logistic Regression but it didn't perform well.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04de7259-0390-444f-864d-3eede16109bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_boost_gs = grid_search(\n",
    "    preprocessor = None, \n",
    "    predictor = AdaBoostClassifier(estimator=DecisionTreeClassifier(random_state=rng), random_state=rng),\n",
    "    param_grid = {\n",
    "        \"predictor__n_estimators\": [200, 250, 300], \n",
    "        \"predictor__estimator__max_depth\": range(10, 13)\n",
    "    },\n",
    "    cv = 5,\n",
    "    metric = \"accuracy\",\n",
    "    X_train = X_train,\n",
    "    y_train = y_train\n",
    ")\n",
    "\n",
    "ada_boost_gs.best_params_, ada_boost_gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6dac727-7619-44bd-8d4a-93489304f2a6",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed9f362-24fb-4333-baf7-cecedf3d4801",
   "metadata": {},
   "source": [
    "In scikit-learn's implementation, this ensemble is made up of trees. (There seems to be some debate about whether scaling is needed or not. Since it does no harm, I've included it.) This one will take an especially long time to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a64a34d-8b32-4e7b-a4de-384f08d6c6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_boost_gs = grid_search(\n",
    "    preprocessor = StandardScaler(), \n",
    "    predictor = GradientBoostingClassifier(random_state=rng),\n",
    "    param_grid = {\n",
    "        \"predictor__n_estimators\": [100, 150, 200],\n",
    "        \"predictor__max_depth\": range(10, 13)\n",
    "    },\n",
    "    cv = 5,\n",
    "    metric = \"accuracy\",\n",
    "    X_train = X_train,\n",
    "    y_train = y_train\n",
    ")\n",
    "\n",
    "gradient_boost_gs.best_params_, gradient_boost_gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2155586c-dc4c-4721-8155-f1e269a3f91f",
   "metadata": {},
   "source": [
    "## How do they all perform on the test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e46974f-1250-4640-926e-c80bfc4ff607",
   "metadata": {},
   "outputs": [],
   "source": [
    "[accuracy_score(model.predict(X_test), y_test) for model in \n",
    "     [decision_tree_gs.best_estimator_, \n",
    "      knn_gs.best_estimator_, \n",
    "      logistic_gs.best_estimator_, \n",
    "      voting_gs.best_estimator_, \n",
    "      bagging_knn_gs.best_estimator_, \n",
    "      random_forest_gs.best_estimator_,\n",
    "      ada_boost_gs.best_estimator_,\n",
    "      gradient_boost_gs.best_estimator_]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d487cac6-29e9-4630-9a1c-1aa20bc58673",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
